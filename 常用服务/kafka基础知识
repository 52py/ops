Kafka是一个分布式的、可分区的、可复制的消息系统。它提供了普通消息系统的功能，但具有自己独特的设计。

基本的概念：
消费者：（Consumer）：从消息队列中请求消息的客户端应用程序
生产者：（Producer） ：向broker发布消息的应用程序
AMQP服务端（broker）：用来接收生产者发送的消息并将这些消息路由给服务器中的队列，便于fafka将生产者发送的消息，动态的添加到磁盘并给每一条消息一个偏移量，所以对于Kafka一个broker就是一个应用程序的实例
主题（Topic）：一个主题类似新闻中的体育、娱乐、教育等分类概念，在实际工程中通常一个业务一个主题。
分区（Partition）：一个Topic中的消息数据按照多个分区组织，分区是Kafka消息队列组织的最小单位，一个分区可以看作是一个FIFO（ First Input First Output的缩写，先入先出队列）的队列。

Kafka将消息以topic为单位进行归纳，每个broker其实就是一个应用服务器，一个broker中会有很多的topic，每个topic其实就是不同的服务需要消息的消息的聚集地。因为每个topic其实会很大，所以就出现了partition
的概念，将每个topic的消息分区存储。

Kafka中的消费者有一个分组的概念，每个consumer属于一个consumer group;反过来说,每个group中可以有多个consumer.发送到Topic的消息,只会被订阅此Topic的每个group中的一个consumer消费（而不是该group下
的所有consumer，一定要注意这点）
如果所有的consumer都具有相同的group,消息将会在consumers之间负载均衡.
如果所有的consumer都具有不同的group,消息将会广播给所有的消费者.

在Kafka中,一个partition中的消息只会被group中的一个consumer消费;每个group中consumer消息消费互相独立;我们可以认为一个group是一个”订阅”者,一个Topic中的每个partions,只会被一个”订阅者”中的一个
consumer消费,不过一个consumer可以消费多个partitions中的消息.
分布式环境中，Kafka默认使用zookeeper作为注册中心，Kafka集群几乎不维护任何consumer和producer的信息状态，这些信息都由zookeeper保存，所以consumer和producer非常的轻量级，随时注册和离开都不会对
Kafka造成震荡。

producer和consumer通过zookeeper去发现topic，并且通过zookeeper来协调生产和消费的过程。
producer、consumer和broker均采用TCP连接，通信基于NIO实现。Producer和consumer能自动检测broker的增加和减少。

partition物理上由多个segment组成，每一个segment 数据文件都有一个索引文件对应。每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个
连续的序列号叫做offset,用于partition唯一标识一条消息.相比传统的消息系统，Kafka可以很好的保证有序性。

通过分区的概念，Kafka可以在多个consumer组并发的情况下提供较好的有序性和负载均衡。将每个分区分只分发给一个consumer组，这样一个分区就只被这个组的一个consumer消费，就可以顺序的消费这个分区的消息。
因为有多个分区，依然可以在多个consumer组之间进行负载均衡。注意consumer组的数量不能多于分区的数量，也就是有多少分区就允许多少并发消费。
Kafka只能保证一个分区之内消息的有序性，在不同的分区之间是不可以的，这已经可以满足大部分应用的需求。如果需要topic中所有消息的有序性，那就只能让这个topic只有一个分区，当然也就只有一个consumer组消
费它。


message 被分配到 partition 的过程
每一条消息被发送到broker时，会根据paritition规则（有两种基本的策略，一是采用Key Hash算法，一是采用Round Robin算法）选择被存储到哪一个partition。如果partition规则设置的合理，所有消息可以均匀
分布到不同的partition里，这样就实现了水平扩展。（如果一个topic对应一个文件，那这个文件所在的机器I/O将会成为这个topic的性能瓶颈，而partition解决了这个问题）。
在发送一条消息时，可以指定这条消息的key，producer根据这个key和partition机制来判断将这条消息发送到哪个parition。paritition机制可以通过指定producer的paritition.class这一参数来指定，该class必
须实现Kafka.producer.Partitioner接口。

broker的注册

Kafka使用Zookeeper来维护集群成员的信息。每个broker都有一个唯一标识符，这个标识符可以在配置文件里指定，也可以自动生成。在kafka启动的时候，他通过创建临节点把自己的id注册到zk，kafka组件订阅zk的
/broker/ids路径(broker在zk上的注册路径)，当有broker加入或者退出集群的时候，这些组件就可以获得通知。
如果当前id所在的broker已经注册然后启动另一个有相同id的broker，启动会出错，新的broker会试着进行注册，但是不会成功。因为zk中已经有一个相同名字的id注册过了。
如果broker出现停机或者网络长时间无响应，broker会从zk断开链接，zk中注册的临时节点会删除，下次broker启动需要重新注册。
如果是关闭broker那么他对应的节点也会消失，但是他的id也许会存在于其他的数据结构中。比如主题对应的副本，在完全关闭一个broker之后如果使用相同的id启动另一个全新的broker，他会立即加入集群，并且会拥
有之前broker所有的主题和分区(前提是没有发生重排序，没有第二个新的broker加入)。


kafka集群leader选举

在kafka集群中，第一个启动的broker会在zk中创建一个临时节点/controller让自己成为控制器。其他broker启动时也会试着创建这个节点当然他们会失败，因为已经有人创建过了。那么这些节点会在控制器节点上创建
zk watch对象，这样他们就可以收到这个节点变更的通知。任何时刻都确保集群中只有一个leader的存在。
如果控制器被关闭或者与zk断开连接，zk上的KB是节点马上就会消失。那么其他订阅了leader节点的broker也会收到通知随后他们会尝试让自己成为新的leader，重复第一步的操作。
如果leader完好但是别的broker离开了集群，那么leader会去确定离开的broker的分区并确认新的分区领导者(即分区副本列表里的下一个副本)。然后向所有包含该副本的follower或者observer发送请求。随后新的分
区首领开始处理请求。


kafka副本
Kafka每个topic的partition有N个副本，其中N是topic的复制因子。Kafka通过多副本机制实现故障自动转移，当Kafka集群中一个Broker失效情况下仍然保证服务可用。在Kafka中发生复制时确保partition的预写式日
志有序地写到其他节点上。N个replicas中。其中一个replica为leader，其他都为follower，leader处理partition的所有读写请求，与此同时，follower会被动定期地去复制leader上的数据。
Kafka必须提供数据复制算法保证,如果leader发生故障或挂掉，一个新leader被选举并接收客户端的消息成功写入。Kafka确保从同步副本列表中选举一个副本为leader,或者换句话说,follower追赶leader数据。leader
负责维护和跟踪ISR中所有follower滞后状态。当生产者发送一条消息到Broker,leader写入消息并复制到所有follower。消息提交之后才被成功复制到所有的同步副本。消息复制延迟受最慢的follower限制,重要的是快速
检测慢副本,如果follower”落后”太多或者失效,leader将会把它从replicas从ISR移除。

kafka的哪些组件需要注册到zookeeper

Broker注册到zk
每个broker启动时，都会注册到zk中，把自身的broker.id通知给zk。待zk创建此节点后，kafka会把这个broker的主机名和端口号记录到此节点。

Topic注册到zk
当broker启动时，会到对应topic节点下注册自己的broker.id到对应分区的isr列表中；当broker退出时，zk会自动更新其对应的topic分区的ISR列表，并决定是否需要做消费者的rebalance

Consumer注册到zk
一旦有新的消费者组注册到zk，zk会创建专用的节点来保存相关信息。如果zk发现消费者增加或减少，会自动触发消费者的负载均衡。

producer不注册到zk










